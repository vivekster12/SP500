---
title: "Trial"
author: "vivek gidla"
date: "June 2, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

# load csv
```{r}
sp500_training_complete<-read.csv("/home/vivek/Documents/sandbox/SandPTrial/S-PTrial/GSPC.csv")
```


# init plot
```{r}
library(ggplot2)
```

```{r plot, echo=FALSE}
ggplot(sp500_training_complete, aes(x=Date, y=Close, group=1)) + geom_line()
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


# need to do min max scaling, but cant use scikit learn, so built own function source: https://gist.github.com/swayson/b5a6d3cd796ab1d08df1

```{r}
minmax_scaler <- function(x, a, b) {
    "
    x: data. numeric vector of values to be scaled
    a: desired minimum after scaling takes place
    b: desired maximum after scaling takes place
    
    e.g. f(c(1,2,3,4), 1, 17)
    [1]  1.000000  6.333333 11.666667 17.000000
    "
    (((b - a)*(x - min(x))) / (max(x) - min(x))) + a
}
```


```{r}
sp500_training_scaled = array(minmax_scaler(sp500_training_complete$Close,0,1))
```



```{r}
N <- 50L
total <- NROW(sp500_training_complete)
```

```{r}
feats <- vector("list",1)
labels <- vector("list",1)
for (index in c(N:(total-1))){
  feats[[(1+index-N)]] <- array(sp500_training_scaled[(1+index-N):index])
  labels[[(1+index-N)]] <- sp500_training_scaled[[(index + 1)]]
}
```

```{r}
library(keras)
use_condaenv("r-tensorflow")
install_keras()
```


```{r}
## TRIAL (see what layer dropout is vs dropout args is)
#model <- keras_model_sequential()
#model %>%
  #layer_lstm(units = 50, return_sequences = TRUE, input_shape=c(N, 1),unroll=FALSE, dropout = 0.2) %>%
  #layer_lstm(units = 50, return_sequences = TRUE, dropout = 0.2) %>%
  #layer_lstm(units = 50, return_sequences = TRUE, dropout = 0.2) %>%
  #layer_lstm(units = 50, dropout = 0.2) %>%
  #layer_dense(units = 1)

```


```{r}
model <- keras_model_sequential()
```

```{r}
model %>%
  layer_lstm(units = 50, return_sequences = TRUE, input_shape=c(N, 1),unroll=FALSE) %>%
  layer_dropout(0.2) %>%
  layer_lstm(units = 50, return_sequences = TRUE) %>%
  layer_dropout(0.2) %>%
  layer_lstm(units = 50, return_sequences = TRUE) %>%
  layer_dropout(0.2) %>%
  layer_lstm(units = 50) %>%
  layer_dropout(0.2) %>%
  layer_dense(units = 1)
  
```


```{r}
summary(model)
```















































